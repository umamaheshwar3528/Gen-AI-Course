{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d83678a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai==1.7.0 in c:\\users\\umred\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from google-genai==1.7.0) (2.38.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from google-genai==1.7.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from google-genai==1.7.0) (4.13.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from google-genai==1.7.0) (15.0.1)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from google-genai==1.7.0) (0.28.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from google-genai==1.7.0) (4.9.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from google-genai==1.7.0) (2.11.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai==1.7.0) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai==1.7.0) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai==1.7.0) (3.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai==1.7.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai==1.7.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai==1.7.0) (4.7.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\umred\\anaconda3\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai==1.7.0) (2021.10.8)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\umred\\anaconda3\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai==1.7.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai==1.7.0) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai==1.7.0) (0.4.8)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai==1.7.0) (0.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai==1.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai==1.7.0) (2.33.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai==1.7.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\umred\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai==1.7.0) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "# Install the Google GenAI SDK\n",
    "!pip install \"google-genai==1.7.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6e47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import HTML, Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8273c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "genai.models.Models.generate_content = retry.Retry(predicate=is_retriable)(genai.models.Models.generate_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe3ce44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Google API key:········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "GOOGLE_API_KEY = getpass.getpass('Enter your Google API key:')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6da1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method generate_content in module google.genai.models:\n",
      "\n",
      "generate_content(*, model: str, contents: Union[list[Union[google.genai.types.Content, list[Union[google.genai.types.File, google.genai.types.Part, PIL.Image.Image, str]], google.genai.types.File, google.genai.types.Part, PIL.Image.Image, str]], google.genai.types.Content, list[Union[google.genai.types.File, google.genai.types.Part, PIL.Image.Image, str]], google.genai.types.File, google.genai.types.Part, PIL.Image.Image, str, list[Union[google.genai.types.Content, list[Union[google.genai.types.File, google.genai.types.Part, PIL.Image.Image, str]], google.genai.types.File, google.genai.types.Part, PIL.Image.Image, str, google.genai.types.ContentDict]], google.genai.types.ContentDict], config: Union[google.genai.types.GenerateContentConfig, google.genai.types.GenerateContentConfigDict, NoneType] = None) -> google.genai.types.GenerateContentResponse method of google.genai.models.Models instance\n",
      "    Makes an API request to generate content using a model.\n",
      "    \n",
      "    For the `model` parameter, supported formats for Vertex AI API include:\n",
      "    - The Gemini model ID, for example: 'gemini-2.0-flash'\n",
      "    - The full resource name starts with 'projects/', for example:\n",
      "      'projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash'\n",
      "    - The partial resource name with 'publishers/', for example:\n",
      "      'publishers/google/models/gemini-2.0-flash' or\n",
      "      'publishers/meta/models/llama-3.1-405b-instruct-maas'\n",
      "    - `/` separated publisher and model name, for example:\n",
      "      'google/gemini-2.0-flash' or 'meta/llama-3.1-405b-instruct-maas'\n",
      "    \n",
      "    For the `model` parameter, supported formats for Gemini API include:\n",
      "    - The Gemini model ID, for example: 'gemini-2.0-flash'\n",
      "    - The model name starts with 'models/', for example:\n",
      "      'models/gemini-2.0-flash'\n",
      "    - For tuned models, the model name starts with 'tunedModels/',\n",
      "      for example:\n",
      "      'tunedModels/1234567890123456789'\n",
      "    \n",
      "    Some models support multimodal input and output.\n",
      "    \n",
      "    Usage:\n",
      "    \n",
      "    .. code-block:: python\n",
      "    \n",
      "      from google.genai import types\n",
      "      from google import genai\n",
      "    \n",
      "      client = genai.Client(\n",
      "          vertexai=True, project='my-project-id', location='us-central1'\n",
      "      )\n",
      "    \n",
      "      response = client.models.generate_content(\n",
      "        model='gemini-2.0-flash',\n",
      "        contents='''What is a good name for a flower shop that specializes in\n",
      "          selling bouquets of dried flowers?'''\n",
      "      )\n",
      "      print(response.text)\n",
      "      # **Elegant & Classic:**\n",
      "      # * The Dried Bloom\n",
      "      # * Everlasting Florals\n",
      "      # * Timeless Petals\n",
      "    \n",
      "      response = client.models.generate_content(\n",
      "        model='gemini-2.0-flash',\n",
      "        contents=[\n",
      "          types.Part.from_text('What is shown in this image?'),\n",
      "          types.Part.from_uri('gs://generativeai-downloads/images/scones.jpg',\n",
      "          'image/jpeg')\n",
      "        ]\n",
      "      )\n",
      "      print(response.text)\n",
      "      # The image shows a flat lay arrangement of freshly baked blueberry\n",
      "      # scones.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.models.generate_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a113a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, imagine you have a really smart toy robot. This robot can learn new things, just like you do!\n",
      "\n",
      "Normally, robots can only do what you program them to do. But AI is like giving the robot a **brain** that lets it learn from examples and figure things out on its own.\n",
      "\n",
      "**Here's how it works:**\n",
      "\n",
      "1.  **You give the robot lots of examples.** Let's say you want it to recognize cats. You show it lots and lots of pictures of cats! Some are fluffy, some are skinny, some are black, some are orange.\n",
      "2.  **The robot looks for patterns.** The robot looks at all those pictures and tries to find things that are the same in all the pictures of cats - pointy ears, whiskers, a tail, etc.\n",
      "3.  **The robot learns to recognize cats!** Now, when you show it a new picture, it can use what it learned to say \"That's a cat!\" Even if it's a cat it's never seen before!\n",
      "\n",
      "**So AI is like teaching a computer to learn and make decisions like a human, but without having to tell it exactly what to do every single time.**\n",
      "\n",
      "**Where do we use AI?**\n",
      "\n",
      "*   **Video games:** To make the computer-controlled characters smarter.\n",
      "*   **Your phone:** To help you take better pictures and to understand what you say.\n",
      "*   **Netflix:** To suggest movies you might like.\n",
      "*   **Cars:** To help them drive themselves (one day!).\n",
      "\n",
      "**AI is still learning too!** It's not perfect, and sometimes it makes mistakes. But it's getting smarter all the time, just like you!\n",
      "\n",
      "**Think of it like this:**  AI is like training a dog. You don't tell the dog *exactly* how to sit, you show it, reward it, and it learns by itself.  AI is the same way, but with computers!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Explain AI to me like I'm a kid.\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75ca638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Uma Maheshwar Reddy! It's nice to meet you. How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(model='gemini-2.0-flash', history=[])\n",
    "response = chat.send_message('Hello! My name is Uma Maheshwar Reddy')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23412987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a fascinating fact about dinosaurs that often surprises people:\n",
      "\n",
      "**Birds are modern-day dinosaurs!**\n",
      "\n",
      "That's right! Scientific evidence overwhelmingly supports the theory that birds evolved directly from small, feathered theropod dinosaurs (the group that includes Velociraptor and Tyrannosaurus Rex).\n",
      "\n",
      "Here's why:\n",
      "\n",
      "*   **Skeletal Similarities:** Birds and theropod dinosaurs share numerous skeletal features, including a wishbone (furcula), hollow bones, and three-fingered hands.\n",
      "*   **Feathers:** The fossil record shows that many non-avian dinosaurs had feathers. Feathers weren't initially for flight; they likely evolved for insulation or display.\n",
      "*   **Eggs:** Birds and dinosaurs lay similar types of eggs with hard shells.\n",
      "*   **DNA Evidence:** Genetic studies have confirmed the close relationship between birds and dinosaurs.\n",
      "\n",
      "So, the next time you see a robin hopping in your garden, remember you're looking at a direct descendant of the mighty dinosaurs!\n",
      "\n",
      "Did you find that interesting? I can share another fact if you'd like!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message('Can you tell me something interesting about dinosaurs?')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "147f16f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, your name is Uma Maheshwar Reddy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message('Do you remember what my name is?')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ca25ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, the title of the most expensive car in the world belongs to the **Rolls-Royce La Rose Noire Droptail**. It was unveiled in August 2023 and costs an estimated **$30 million USD**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message('expensive car in the world')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18829d46",
   "metadata": {},
   "source": [
    "# Different Models available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7631fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "  print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2e08736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Gemini 2.0 Flash',\n",
      " 'display_name': 'Gemini 2.0 Flash',\n",
      " 'input_token_limit': 1048576,\n",
      " 'name': 'models/gemini-2.0-flash',\n",
      " 'output_token_limit': 8192,\n",
      " 'supported_actions': ['generateContent', 'countTokens'],\n",
      " 'tuned_model_info': {},\n",
      " 'version': '2.0'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for model in client.models.list():\n",
    "  if model.name == 'models/gemini-2.0-flash':\n",
    "    pprint(model.to_json_dict())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5616b",
   "metadata": {},
   "source": [
    "# Output length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1890b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## The Humble Olive: A Cornerstone of Modern Society\n",
      "\n",
      "The olive, that small, unassuming fruit of the *Olea europaea* tree, boasts a history as rich and gnarled as its ancient branches. Far from being a mere garnish or pizza topping, the olive and its derivatives, particularly olive oil, have woven themselves inextricably into the fabric of modern society. Its influence extends beyond culinary landscapes, permeating health, economics, culture, and even sustainable practices, solidifying its position as a vital component of our interconnected world.\n",
      "\n",
      "One of the most significant contributions of the olive to modern society is its profound impact on human health. Olive oil, in particular, has gained widespread recognition as a cornerstone of the Mediterranean Diet, a dietary pattern repeatedly linked to reduced risk of cardiovascular disease, certain cancers, and neurodegenerative conditions like Alzheimer's. The monounsaturated fatty acids, primarily oleic acid, found abundantly in olive oil, are key to these benefits. They help lower \"bad\"\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "short_config = types.GenerateContentConfig(max_output_tokens=200)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=short_config,\n",
    "    contents='Write a 1000 word essay on the importance of olives in modern society.')\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066562d9",
   "metadata": {},
   "source": [
    "# Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4c78a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magenta\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Teal\n",
      " -------------------------\n",
      "Magenta\n",
      " -------------------------\n"
     ]
    }
   ],
   "source": [
    "high_temp_config = types.GenerateContentConfig(temperature=2.0)\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "  response = client.models.generate_content(\n",
    "      model='gemini-2.0-flash',\n",
    "      config=high_temp_config,\n",
    "      contents='Pick a random colour... (respond in a single word)')\n",
    "\n",
    "  if response.text:\n",
    "    print(response.text, '-' * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc9996ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n"
     ]
    }
   ],
   "source": [
    "low_temp_config = types.GenerateContentConfig(temperature=0.0)\n",
    "\n",
    "for _ in range(5):\n",
    "  response = client.models.generate_content(\n",
    "      model='gemini-2.0-flash',\n",
    "      config=low_temp_config,\n",
    "      contents='Pick a random colour... (respond in a single word)')\n",
    "\n",
    "  if response.text:\n",
    "    print(response.text, '-' * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66841136",
   "metadata": {},
   "source": [
    "# Top-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4fc7637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clementine was no ordinary cat. Oh, she loved a sunbeam nap and a saucer of tuna, but beneath her sleek, calico coat beat the heart of an explorer. While her humans, the elderly Mr. and Mrs. Higgins, were content with their routine of tea and crossword puzzles, Clementine dreamt of the sprawling, mysterious world beyond their picket fence.\n",
      "\n",
      "One breezy autumn afternoon, the door to the garden was carelessly left ajar. Clementine, perched on the windowsill, saw her chance. With a flick of her tail and a silent apology to the robins she usually terrorized, she slipped through the opening and onto the forbidden grass.\n",
      "\n",
      "The world exploded with scent. Decaying leaves, damp earth, the tantalizing aroma of Mr. Peterson's prize-winning roses. Clementine, intoxicated by the sensory overload, padded forward, her whiskers twitching with curiosity.\n",
      "\n",
      "Her journey led her to the Whispering Woods, a tangled thicket bordering the Higgins' garden. She had only seen it from afar, a dark, impenetrable mass. Now, she was inside, sunlight dappling through the leaves, painting the forest floor in shifting patterns.\n",
      "\n",
      "Suddenly, a flash of emerald caught her eye. A hummingbird, trapped in a spiderweb, buzzed frantically. Clementine, normally a predator, felt a surge of empathy. She carefully extended a paw, delicately severing the sticky strands. The hummingbird, freed, hovered for a moment, as if in gratitude, then zipped away.\n",
      "\n",
      "Deeper into the woods she ventured, her senses heightened. She encountered a grumpy hedgehog, a family of scurrying squirrels, and a wise old owl perched on a branch, its yellow eyes gleaming in the twilight. Each encounter was a lesson, a glimpse into a world she had only imagined.\n",
      "\n",
      "As dusk began to settle, Clementine realized she was lost. Panic, a foreign emotion, tightened in her chest. She meowed, a tiny, lost sound swallowed by the vastness of the woods.\n",
      "\n",
      "Then, a familiar scent. Roses. Mr. Peterson's prize-winning roses. With renewed hope, she followed the fragrance, pushing through the undergrowth.\n",
      "\n",
      "And there it was. A sliver of light, the edge of the Whispering Woods, and beyond it, her own garden. She scrambled through the opening, a rush of relief washing over her.\n",
      "\n",
      "The Higgins' were frantic, calling her name. Mrs. Higgins scooped her up, burying her face in Clementine's fur. \"Oh, Clementine, we were so worried!\"\n",
      "\n",
      "Clementine purred, a rumbling vibration that shook her whole body. She allowed herself to be fussed over, to be fed a double portion of tuna. But as she settled onto her favorite cushion by the fire, she knew she wouldn't forget her adventure.\n",
      "\n",
      "The world beyond the picket fence was wild, and sometimes frightening, but it was also full of wonder and unexpected friendships. Clementine, the ordinary house cat, had discovered a secret: she was also an explorer, and the world was her oyster, or perhaps, her particularly delicious tuna. The next adventure, she knew, was already waiting. She just needed to find the slightly ajar door.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    # These are the default values for gemini-2.0-flash.\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "story_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=story_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efa979eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clementine, a ginger tabby of impeccable fluff and insatiable curiosity, was bored. Terribly, utterly, devastatingly bored. Her days were a monotonous cycle of naps in sunbeams, chasing dust bunnies, and demanding head scratches from her human, a kind but predictable librarian named Agnes. \n",
      "\n",
      "One Tuesday, Agnes left the back door ajar. The forbidden world, a verdant explosion of untamed green, beckoned. Clementine, with a flick of her tail, decided boredom was officially over.\n",
      "\n",
      "Her adventure began with a hesitant step onto cool, damp earth. The scent of blooming honeysuckle and damp moss exploded in her nostrils. She crept beneath a towering rose bush, its thorns a shimmering fortress. A plump bumblebee, buzzing with indignant fury, nearly collided with her nose. Clementine, mesmerized, forgot her predatory instincts and simply watched it blunder off.\n",
      "\n",
      "The garden was a labyrinth of wonders. She scaled a wobbly bird feeder, sending sunflower seeds scattering like golden rain. She stalked a particularly arrogant robin, her tail twitching with the thrill of the chase, only to be outwitted by the bird's aerial agility.\n",
      "\n",
      "Deeper into the wild unknown, Clementine encountered a grumpy hedgehog, huddled amongst fallen leaves. The hedgehog, bristling with suspicion, huffed and puffed until Clementine, intimidated by its prickly demeanor, backed down.\n",
      "\n",
      "Then, she heard it. A faint, plaintive meow. Following the sound, she found a tiny black kitten, no bigger than her paw, trapped at the bottom of a disused watering can. The kitten trembled, its wide, scared eyes reflecting the sky.\n",
      "\n",
      "Clementine, forgetting her fear of prickly hedgehogs and arrogant robins, knew she had to help. She nudged the watering can, trying to tip it over. It was too heavy. She meowed, a loud, urgent cry, hoping someone would hear.\n",
      "\n",
      "A rustle in the bushes. Agnes! Her human, face creased with worry, scooped up the little kitten and, to Clementine's surprise, scooped up Clementine too.\n",
      "\n",
      "\"You little rascal!\" Agnes chuckled, nuzzling Clementine's head. \"Getting into trouble already, and saving a life too!\"\n",
      "\n",
      "Back inside, curled up on her favorite cushion, Clementine felt a profound sense of satisfaction. The garden, the bumblebee, the hedgehog, the terrified kitten - it had all been exhilarating, terrifying, and utterly worthwhile. \n",
      "\n",
      "Agnes placed the black kitten in a box lined with soft towels. It mewled weakly, then nestled against Clementine, purring a shaky, grateful rumble. Clementine licked its tiny head, a gesture of acceptance, of belonging.\n",
      "\n",
      "That night, curled up with the kitten and Agnes, Clementine realized adventure wasn't just about exploring the unknown. It was about finding something, or someone, worth saving. And that, she decided, was the best kind of adventure of all. The sunbeams and head scratches could wait. For now, Clementine had a little black shadow, a tiny friend, and a whole new world to explore, right here at home.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    # These are the default values for gemini-2.0-flash.\n",
    "    temperature=1.5,\n",
    "    top_p=0.85,\n",
    ")\n",
    "\n",
    "story_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=story_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94f9b3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clementine was no ordinary cat. While her ginger siblings napped sunbeams away and chased dust bunnies, Clementine dreamt of the Whispering Woods. They bordered the human's, Rosie's, garden, a tangled tapestry of green that shivered with unseen secrets. Rosie warned against it, \"Too many prickly things, Clementine! And foxes!\"\n",
      "\n",
      "But Clementine yearned. One crisp autumn morning, the scent of damp leaves and woodsmoke proved too alluring. She slipped through a gap in the fence, her amber eyes wide with exhilaration.\n",
      "\n",
      "The woods hummed. Towering trees clawed at the sky, their leaves a symphony of rust and gold. Clementine, used to the smooth, clipped grass of Rosie's garden, found the uneven terrain a delight. Every rustle of a leaf, every snap of a twig, was a new mystery.\n",
      "\n",
      "She stalked a fat earthworm, batted at a falling acorn, and even dared to hiss at a grumpy hedgehog, its quills bristling like tiny daggers. The woods were alive!\n",
      "\n",
      "Deeper she ventured, drawn by the sound of trickling water. She found a ribbon of a stream, its surface shimmering with sunlight. On the opposite bank perched a raven, its ebony feathers gleaming. Clementine had never seen a bird so close.\n",
      "\n",
      "\"Lost, little one?\" the raven croaked, its voice surprisingly melodic.\n",
      "\n",
      "Clementine, usually quick to meow a response, was momentarily speechless. \"Just... exploring,\" she finally managed.\n",
      "\n",
      "\"The Whispering Woods are not to be taken lightly,\" the raven warned, tilting its head. \"They hold many secrets, and some are best left undisturbed.\"\n",
      "\n",
      "Clementine ignored the warning. Curiosity, the fuel of every great adventure, burned in her chest. She leaped across the stream, landing nimbly on the mossy bank. The raven watched her, its obsidian eyes knowing.\n",
      "\n",
      "She followed the stream upwards, towards a low, rumbling sound. Rounding a bend, she gasped. A waterfall cascaded down a sheer rock face, forming a small, clear pool below. But it wasn't the waterfall that stole her breath.\n",
      "\n",
      "Behind the waterfall, concealed by the falling curtain of water, was a cave. A shimmering, almost translucent curtain of water obscured its entrance.\n",
      "\n",
      "Clementine knew, with a certainty that settled deep in her bones, that she had to go in.\n",
      "\n",
      "She hesitated. Rosie's warnings flashed through her mind: prickly things... foxes... But the allure of the unknown was too strong. She took a deep breath, closed her eyes, and plunged through the waterfall.\n",
      "\n",
      "The water was shockingly cold, but only for a moment. Then, she was inside.\n",
      "\n",
      "The cave was damp and cool, illuminated by an ethereal glow that seemed to emanate from the very rocks themselves. The air hummed with a quiet energy. Deeper inside, she saw it: a cluster of moonstone crystals, their surfaces shimmering with otherworldly light.\n",
      "\n",
      "They pulsed gently, casting dancing shadows on the cave walls. Clementine felt drawn to them, as if they held the secrets of the universe. She touched one with her nose.\n",
      "\n",
      "Suddenly, a vision flooded her mind: vast, starlit skies, creatures with wings of fire, and landscapes that defied description. The image vanished as quickly as it appeared, leaving her breathless and disoriented.\n",
      "\n",
      "Scared but exhilarated, Clementine knew she had experienced something extraordinary. It was time to go home.\n",
      "\n",
      "She retraced her steps, grateful for the familiar scent of Rosie's garden. As she slipped back through the fence, Rosie called out, \"Clementine! Where have you been? I was so worried!\"\n",
      "\n",
      "Rosie scooped her up, burying her face in Clementine's soft fur. \"Don't scare me like that again,\" she murmured.\n",
      "\n",
      "Clementine purred, nuzzling into Rosie's neck. She wouldn't tell Rosie about the Whispering Woods, or the raven, or the shimmering crystals. Some secrets were best kept close.\n",
      "\n",
      "That night, as she curled up on Rosie's lap, Clementine dreamt of the starlit skies and creatures with wings of fire. She knew her adventures in the Whispering Woods were just beginning. The world was bigger, wilder, and more magical than she ever imagined, and she, Clementine, was ready to explore it all.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    # These are the default values for gemini-2.0-flash.\n",
    "    temperature=1.0,\n",
    "    top_p= 1,\n",
    ")\n",
    "\n",
    "story_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=story_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb43c91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clementine, a calico of discerning tastes and a perpetually unimpressed expression, considered her life utterly predictable. Sunbeam naps, chasing dust bunnies, the occasional disdainful glance at the goldfish – it was all terribly…beige. She yearned for something more, a splash of vibrant color in her monochrome existence.\n",
      "\n",
      "One blustery autumn afternoon, the back door, usually bolted tighter than a miser's purse, was ajar. A tantalizing gust of wind, carrying the scent of damp earth and decaying leaves, beckoned. Clementine, abandoning her nap mid-yawn, slipped through the crack.\n",
      "\n",
      "The world outside was a riot of sensory overload. Towering trees, their leaves ablaze in fiery hues, whispered secrets in the wind. Squirrels, plump and frantic, chattered insults from branches. Clementine, usually content with the confines of her sun-drenched windowsill, felt a thrill course through her. This was it. Adventure.\n",
      "\n",
      "Her first challenge was the garden. A jungle of overgrown rose bushes, their thorns like tiny daggers, guarded the path. Clementine, with the agility of a seasoned acrobat, navigated the thorny maze, her tail twitching with determination.\n",
      "\n",
      "Beyond the garden lay a field, a sea of golden grass swaying in the wind. A fat bumblebee, buzzing lazily, became her next target. A playful pounce, a clumsy swat, and the bee, unimpressed, buzzed off, leaving Clementine with a slightly stung paw and a bruised ego.\n",
      "\n",
      "Undeterred, she pressed on, drawn by the sound of rushing water. She found a stream, its surface shimmering like liquid diamonds. A tiny, silver fish darted beneath the surface. Clementine, forgetting her usual disdain for aquatic life, crouched low, her hunter instincts kicking in. She stalked, she waited, she pounced!\n",
      "\n",
      "She landed with a splash, the icy water shocking her to her core. The fish, of course, was long gone. Soaked and shivering, Clementine realized adventure wasn't all sunshine and roses (or, in her case, sunshine and dust bunnies).\n",
      "\n",
      "As dusk began to paint the sky in shades of purple and orange, a wave of homesickness washed over her. The familiar scent of tuna wafted on the breeze, a siren call she couldn't resist.\n",
      "\n",
      "She retraced her steps, navigating the thorny rose bushes with newfound respect, crossing the field with a weary sigh. The back door, still ajar, welcomed her back into the warm embrace of her home.\n",
      "\n",
      "Her human, oblivious to her grand adventure, simply scooped her up, cooing, \"Where have you been, my little darling?\"\n",
      "\n",
      "Clementine purred, rubbing against her human's cheek. She didn't tell her about the field, the stream, or the bumblebee. Some adventures, she decided, were best kept secret.\n",
      "\n",
      "As she curled up on her favorite sunbeam spot, a faint scent of damp earth clung to her fur. Her life might still be predictable, but now, it held a secret, a splash of vibrant color only she knew. And that, Clementine thought, was enough. For now.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    # These are the default values for gemini-2.0-flash.\n",
    "    temperature= 0,\n",
    "    top_p= 0,\n",
    ")\n",
    "\n",
    "story_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=story_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dff46d",
   "metadata": {},
   "source": [
    "# Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca6296",
   "metadata": {},
   "source": [
    "## Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0ce272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    temperature=0.1,\n",
    "    top_p=1,\n",
    "    max_output_tokens=5,\n",
    ")\n",
    "\n",
    "zero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\n",
    "Review: \"Her\" is a disturbing study revealing the direction\n",
    "humanity is headed if AI is allowed to keep evolving,\n",
    "unchecked. I wish there were more movies like this masterpiece.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=zero_shot_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58cabb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    temperature=0.1,\n",
    "    top_p= 0,\n",
    "    max_output_tokens=10,\n",
    ")\n",
    "\n",
    "zero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\n",
    "Review: \"Her\" is a disturbing study revealing the direction\n",
    "humanity is headed if AI is allowed to keep evolving,\n",
    "unchecked. I wish there were more movies like this masterpiece.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=zero_shot_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87454376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few catchy descriptions for a smartphone with a 108MP camera, 5000mAh battery, and 5G support, catering to different target audiences:\n",
      "\n",
      "**Option 1 (Focus on Camera):**\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    temperature=0.7,  # More creative responses\n",
    "    top_p=1,\n",
    "    max_output_tokens=50\n",
    ")\n",
    "\n",
    "product_prompt = \"\"\"Generate a catchy description for a new smartphone that features a 108MP camera, 5000mAh battery, and 5G support.\n",
    "Product: \"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=product_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1528dcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Caprese Skewers with Balsamic Glaze**\n",
      "\n",
      "**Description:** A simple, elegant, and refreshing appetizer or light snack that showcases the classic combination of tomatoes, basil, and mozzarella. Perfect for parties or a quick and easy summer treat.\n",
      "\n",
      "**Ingredients:**\n",
      "\n",
      "*   1 pint cherry tomatoes (or grape tomatoes), preferably multi-colored for visual appeal\n",
      "*   8 oz fresh mozzarella balls (bocconcini), small or medium size\n",
      "*   1 bunch fresh basil leaves, small to medium size\n",
      "*   Balsamic glaze (store-bought or homemade)\n",
      "*   Olive oil (optional)\n",
      "*   Salt and freshly ground black pepper to taste\n",
      "*   Wooden skewers\n",
      "\n",
      "**Instructions:**\n",
      "\n",
      "1.  **Prepare the Ingredients:** Wash and dry the cherry tomatoes and basil leaves. Drain the mozzarella balls, if packed in water.\n",
      "2.  **Assemble the Skewers:** Thread a tomato, a basil leaf, and a mozzarella ball onto each skewer. Repeat the pattern until the skewer is almost full, leaving a little space at the end for easy handling. Aim for about 3-4 of each ingredient per skewer, depending on their size and the length of your skewers.\n",
      "3.  **Arrange and Drizzle:** Arrange the assembled skewers on a serving platter.\n",
      "4.  **Season (Optional):** Lightly drizzle the skewers with olive oil (optional). Season with salt and freshly ground black pepper to taste.\n",
      "5.  **Drizzle with Balsamic Glaze:** Drizzle generously with balsamic glaze just before serving.\n",
      "\n",
      "**Tips and Variations:**\n",
      "\n",
      "*   **Homemade Balsamic Glaze:** To make your own balsamic glaze, simmer balsamic vinegar in a small saucepan over low heat until it reduces and thickens to a syrupy consistency.\n",
      "*   **Marinated Mozzarella:** Marinate the mozzarella balls in olive oil, garlic, and herbs for extra flavor.\n",
      "*   **Prosciutto:** Add a slice of prosciutto to each skewer for a savory twist.\n",
      "*   **Different Tomatoes:** Use heirloom tomatoes, sliced into wedges, for a more substantial bite.\n",
      "*   **Presentation:** Garnish the platter with extra basil leaves or a drizzle of balsamic glaze.\n",
      "*   **Make Ahead:** You can assemble the skewers a few hours in advance. Cover and refrigerate until ready to serve. Add the balsamic glaze just before serving to prevent the basil from wilting.\n",
      "*   **Vegan Option:** Substitute the mozzarella with vegan mozzarella balls.\n",
      "\n",
      "Enjoy!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    temperature=0.6,\n",
    "    top_p=1,\n",
    "    max_output_tokens=1000\n",
    ")\n",
    "\n",
    "recipe_prompt = \"\"\"Generate a recipe idea using the following ingredients: tomatoes, basil, and mozzarella cheese.\n",
    "Recipe: \"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=recipe_prompt)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf662a",
   "metadata": {},
   "source": [
    "## Enum Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dba44c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "import enum\n",
    "\n",
    "class Sentiment(enum.Enum):\n",
    "    POSITIVE = \"positive\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "    NEGATIVE = \"negative\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"text/x.enum\",\n",
    "        response_schema=Sentiment\n",
    "    ),\n",
    "    contents=zero_shot_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ee19264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment.POSITIVE\n",
      "<enum 'Sentiment'>\n"
     ]
    }
   ],
   "source": [
    "enum_response = response.parsed\n",
    "print(enum_response)\n",
    "print(type(enum_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3f5be",
   "metadata": {},
   "source": [
    "## One-shot and few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b16f4bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\"size\": \"large\",\n",
      "\"type\": \"normal\",\n",
      "\"ingredients\": [\"cheese\", \"pineapple\"]\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\"Parse a customer's pizza order into valid JSON:\n",
    "\n",
    "EXAMPLE:\n",
    "I want a small pizza with cheese, tomato sauce, and pepperoni.\n",
    "JSON Response:\n",
    "```\n",
    "{\n",
    "\"size\": \"small\",\n",
    "\"type\": \"normal\",\n",
    "\"ingredients\": [\"cheese\", \"tomato sauce\", \"pepperoni\"]\n",
    "}\n",
    "```\n",
    "\n",
    "EXAMPLE:\n",
    "Can I get a large pizza with tomato sauce, basil and mozzarella\n",
    "JSON Response:\n",
    "```\n",
    "{\n",
    "\"size\": \"large\",\n",
    "\"type\": \"normal\",\n",
    "\"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n",
    "}\n",
    "```\n",
    "\n",
    "ORDER:\n",
    "\"\"\"\n",
    "\n",
    "customer_order = \"Give me a large with cheese & pineapple\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.1,\n",
    "        top_p=1,\n",
    "        max_output_tokens=250,\n",
    "    ),\n",
    "    contents=[few_shot_prompt, customer_order])\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdc398d",
   "metadata": {},
   "source": [
    "## JSON mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "192ecad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"size\": \"large\",\n",
      "  \"ingredients\": [\"apple\", \"chocolate\"],\n",
      "  \"type\": \"dessert\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import typing_extensions as typing\n",
    "\n",
    "class PizzaOrder(typing.TypedDict):\n",
    "    size: str\n",
    "    ingredients: list[str]\n",
    "    type: str\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.1,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=PizzaOrder,\n",
    "    ),\n",
    "    contents=\"Can I have a large dessert pizza with apple and chocolate\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb955b4d",
   "metadata": {},
   "source": [
    "# Chain of Thought (CoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5bc6d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now, I\n",
    "am 20 years old. How old is my partner? Return the answer directly.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ebc16d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's how to solve this step by step:\n",
       "\n",
       "1. **Find the age difference:** When you were 4, your partner was 3 times your age, meaning they were 4 * 3 = 12 years old.\n",
       "\n",
       "2. **Calculate the age gap:** The age difference between you and your partner is 12 - 4 = 8 years.\n",
       "\n",
       "3. **Determine partner's current age:** Since the age difference remains constant, your partner is always 8 years older than you. Now that you are 20, your partner is 20 + 8 = 28 years old.\n",
       "\n",
       "**Therefore, your partner is currently 28 years old.**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now,\n",
    "I am 20 years old. How old is my partner? Let's think step by step.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=prompt)\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69fd15",
   "metadata": {},
   "source": [
    "# ReAct: Reason and act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8150909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instructions = \"\"\"\n",
    "Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation,\n",
    "Observation is understanding relevant information from an Action's output and Action can be one of three types:\n",
    " (1) <search>entity</search>, which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it\n",
    "     will return some similar entities to search and you can try to search the information from those topics.\n",
    " (2) <lookup>keyword</lookup>, which returns the next sentence containing keyword in the current context. This only does exact matches,\n",
    "     so keep your searches short.\n",
    " (3) <finish>answer</finish>, which returns the answer and finishes the task.\n",
    "\"\"\"\n",
    "\n",
    "example1 = \"\"\"Question\n",
    "Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n",
    "\n",
    "Thought 1\n",
    "The question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n",
    "\n",
    "Action 1\n",
    "<search>Milhouse</search>\n",
    "\n",
    "Observation 1\n",
    "Milhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n",
    "\n",
    "Thought 2\n",
    "The paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n",
    "\n",
    "Action 2\n",
    "<lookup>named after</lookup>\n",
    "\n",
    "Observation 2\n",
    "Milhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n",
    "\n",
    "Thought 3\n",
    "Milhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n",
    "\n",
    "Action 3\n",
    "<finish>Richard Nixon</finish>\n",
    "\"\"\"\n",
    "\n",
    "example2 = \"\"\"Question\n",
    "What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n",
    "\n",
    "Thought 1\n",
    "I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n",
    "\n",
    "Action 1\n",
    "<search>Colorado orogeny</search>\n",
    "\n",
    "Observation 1\n",
    "The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n",
    "\n",
    "Thought 2\n",
    "It does not mention the eastern sector. So I need to look up eastern sector.\n",
    "\n",
    "Action 2\n",
    "<lookup>eastern sector</lookup>\n",
    "\n",
    "Observation 2\n",
    "The eastern sector extends into the High Plains and is called the Central Plains orogeny.\n",
    "\n",
    "Thought 3\n",
    "The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n",
    "\n",
    "Action 3\n",
    "<search>High Plains</search>\n",
    "\n",
    "Observation 3\n",
    "High Plains refers to one of two distinct land regions\n",
    "\n",
    "Thought 4\n",
    "I need to instead search High Plains (United States).\n",
    "\n",
    "Action 4\n",
    "<search>High Plains (United States)</search>\n",
    "\n",
    "Observation 4\n",
    "The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130m).\n",
    "\n",
    "Thought 5\n",
    "High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n",
    "\n",
    "Action 5\n",
    "<finish>1,800 to 7,000 ft</finish>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d82d1ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 1\n",
      "I need to find the transformers NLP paper and then identify the youngest author listed on that paper.\n",
      "\n",
      "Action 1\n",
      "<search>transformers NLP paper</search>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Question\n",
    "Who was the youngest author listed on the transformers NLP paper?\n",
    "\"\"\"\n",
    "\n",
    "# You will perform the Action; so generate up to, but not including, the Observation.\n",
    "react_config = types.GenerateContentConfig(\n",
    "    stop_sequences=[\"\\nObservation\"],\n",
    "    system_instruction=model_instructions + example1 + example2,\n",
    ")\n",
    "\n",
    "# Create a chat that has the model instructions and examples pre-seeded.\n",
    "react_chat = client.chats.create(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=react_config,\n",
    ")\n",
    "\n",
    "resp = react_chat.send_message(question)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baf979c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 5\n",
      "I am having trouble finding information about the authors' ages directly. Since it's difficult to determine their ages, I'll try a different approach. I'll look for any information about their education or career paths around the time the paper was published. This might give me a clue about who was likely the youngest. Aidan N. Gomez seems like a plausible answer given the name and the field. I will try to find information about him.\n",
      "\n",
      "Action 5\n",
      "<search>Aidan N. Gomez</search>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "observation = \"\"\"Observation 1\n",
    "[1706.03762] Attention Is All You Need\n",
    "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
    "We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n",
    "\"\"\"\n",
    "resp = react_chat.send_message(observation)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7f83f",
   "metadata": {},
   "source": [
    "# Thinking Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4d07558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the author list of the \"Attention is All You Need\" paper, which introduced the Transformer architecture in NLP, the **youngest author is likely Aidan N. Gomez.**\n",
       "\n",
       "Here's why:\n",
       "\n",
       "* **Aidan N. Gomez** was a PhD student at the University of Toronto at the time of the paper's publication in 2017.  Being a PhD student generally indicates an earlier stage in one's research career compared to researchers at Google Brain and other established institutions.\n",
       "\n",
       "* The other authors were associated with Google Brain and other established research groups, suggesting they were likely more senior in their careers at the time.\n",
       "\n",
       "**Important Note:**\n",
       "\n",
       "* **\"Youngest\" is based on career stage, not necessarily chronological age.**  We don't have the birthdates of all authors to definitively say who was chronologically youngest. However, based on typical academic career paths, a PhD student is generally considered to be at a younger career stage than researchers at established labs like Google Brain.\n",
       "\n",
       "* **The author list of \"Attention is All You Need\" is:** Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin.\n",
       "\n",
       "Therefore, while we can't be 100% certain without knowing everyone's exact birthdate, **Aidan N. Gomez is the most likely answer to \"youngest author\" based on career stage at the time of publication.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "from IPython.display import Markdown, clear_output\n",
    "\n",
    "\n",
    "response = client.models.generate_content_stream(\n",
    "    model='gemini-2.0-flash-thinking-exp',\n",
    "    contents='Who was the youngest author listed on the transformers NLP paper?',\n",
    ")\n",
    "\n",
    "buf = io.StringIO()\n",
    "for chunk in response:\n",
    "    buf.write(chunk.text)\n",
    "    # Display the response as it is streamed\n",
    "    print(chunk.text, end='')\n",
    "\n",
    "# And then render the finished response as formatted markdown.\n",
    "clear_output()\n",
    "Markdown(buf.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97bb6ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Currently, the title of **youngest billionaire** is often attributed to **Kevin David Lehmann**.\n",
       "\n",
       "Here's what we know about him:\n",
       "\n",
       "* **Age when he became a billionaire:** He inherited his stake in the German drugstore chain **dm-drogerie markt** when he was **18 years old**. This happened in 2021 when his father, Günther Lehmann, transferred his shares to him.\n",
       "* **Source of wealth:** Inheritance. He inherited a 50% stake in dm-drogerie markt from his father.\n",
       "* **Company:** dm-drogerie markt is a large and successful drugstore chain in Germany and across Europe.\n",
       "\n",
       "**Important Considerations and Nuances:**\n",
       "\n",
       "* **Inheritance vs. Self-Made:**  It's crucial to note that Kevin David Lehmann's billionaire status is due to inheritance, not building a business from scratch.  This is a significant distinction when discussing \"youngest billionaires.\"  Many people are more interested in individuals who became billionaires through their own entrepreneurial efforts.\n",
       "* **Kylie Jenner:**  For a time, Kylie Jenner was touted as the \"youngest self-made billionaire.\" However, Forbes later retracted this claim, stating that her wealth was inflated and that her business was not entirely \"self-made\" due to her already famous background and family wealth.  Even if those claims hadn't been retracted, she would have been older than Kevin David Lehmann when she achieved billionaire status.\n",
       "* **Rankings Change:**  Billionaire lists and rankings are dynamic. They fluctuate based on market conditions, company valuations, and personal wealth changes.  The \"youngest billionaire\" title can shift.\n",
       "* **Clemente Del Vecchio:**  Another very young billionaire who is often mentioned is Clemente Del Vecchio, also an heir. He inherited a significant stake in EssilorLuxottica, the eyewear giant, after his father's death.  He became a billionaire around the same time as Kevin David Lehmann and is also very young.  Sometimes, depending on the specific ranking and date, he might be listed as the youngest, or very close to it.\n",
       "\n",
       "**In summary, while the title can be debated and rankings shift, currently, Kevin David Lehmann, who inherited his fortune at 18, is widely considered the youngest billionaire. It's important to understand that his wealth is based on inheritance, not self-made entrepreneurial success.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "from IPython.display import Markdown, clear_output\n",
    "\n",
    "\n",
    "response = client.models.generate_content_stream(\n",
    "    model='gemini-2.0-flash-thinking-exp',\n",
    "    contents='Who was the youngest billionare?',\n",
    ")\n",
    "\n",
    "buf = io.StringIO()\n",
    "for chunk in response:\n",
    "    buf.write(chunk.text)\n",
    "    # Display the response as it is streamed\n",
    "    print(chunk.text, end='')\n",
    "\n",
    "# And then render the finished response as formatted markdown.\n",
    "clear_output()\n",
    "Markdown(buf.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4686fbce",
   "metadata": {},
   "source": [
    "# Code Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c528f040",
   "metadata": {},
   "source": [
    "## Generating Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02683748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import argparse\n",
       "\n",
       "def arg_operations(args=None):\n",
       "    parser = argparse.ArgumentParser(description=\"Perform operations based on arguments.\")\n",
       "\n",
       "    # Required positional arguments\n",
       "    parser.add_argument(\"operation\", choices=[\"add\", \"subtract\", \"multiply\", \"divide\"],\n",
       "                        help=\"The operation to perform\")\n",
       "    parser.add_argument(\"num1\", type=float, help=\"The first number\")\n",
       "    parser.add_argument(\"num2\", type=float, help=\"The second number\")\n",
       "\n",
       "    # Optional arguments\n",
       "    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\", help=\"Increase output verbosity\")\n",
       "    parser.add_argument(\"-r\", \"--round\", type=int, help=\"Round the result to this many decimal places\")\n",
       "\n",
       "    # Use the provided arguments or parse from command line\n",
       "    if args:\n",
       "        parsed_args = parser.parse_args(args)\n",
       "    else:\n",
       "        parsed_args = parser.parse_args()\n",
       "\n",
       "    num1 = parsed_args.num1\n",
       "    num2 = parsed_args.num2\n",
       "    operation = parsed_args.operation\n",
       "    verbose = parsed_args.verbose\n",
       "    round_to = parsed_args.round\n",
       "\n",
       "    if operation == \"add\":\n",
       "        result = num1 + num2\n",
       "    elif operation == \"subtract\":\n",
       "        result = num1 - num2\n",
       "    elif operation == \"multiply\":\n",
       "        result = num1 * num2\n",
       "    elif operation == \"divide\":\n",
       "        if num2 == 0:\n",
       "            return \"Error: Cannot divide by zero\"\n",
       "        result = num1 / num2\n",
       "\n",
       "    if round_to is not None:\n",
       "        result = round(result, round_to)\n",
       "\n",
       "    if verbose:\n",
       "        print(f\"Operation: {operation}\")\n",
       "        print(f\"Number 1: {num1}\")\n",
       "        print(f\"Number 2: {num2}\")\n",
       "        print(f\"Result: {result}\")\n",
       "\n",
       "    return result\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    # Example usage:\n",
       "    # To run from command line:  python your_script_name.py add 5.0 2.5 -v -r 2\n",
       "    result = arg_operations()\n",
       "    if isinstance(result, str):\n",
       "        print(result) # print error message\n",
       "    else:\n",
       "        print(result)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Gemini models love to talk, so it helps to specify they stick to the code if that\n",
    "# is all that you want.\n",
    "code_prompt = \"\"\"\n",
    "Write a Python function for arg operations. No explanation, provide only the code.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        max_output_tokens=1024,\n",
    "    ),\n",
    "    contents=code_prompt)\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af51306d",
   "metadata": {},
   "source": [
    "## Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "672d8033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Okay, I can do that. First, I need to generate the first 14 odd '\n",
      "         \"prime numbers. Then, I'll calculate their sum.\\n\"\n",
      "         '\\n'\n",
      "         \"Here's how I'll approach this:\\n\"\n",
      "         '1.  Identify the first few odd prime numbers.\\n'\n",
      "         '2.  Continue identifying odd prime numbers until I have 14 of them. '\n",
      "         'A prime number is a number greater than 1 that has only two factors: '\n",
      "         '1 and itself. An odd prime is simply a prime number that is odd.\\n'\n",
      "         '3.  Sum these 14 prime numbers.\\n'\n",
      "         '\\n'\n",
      "         \"Let's start! The first few odd prime numbers are 3, 5, 7, 11, and \"\n",
      "         \"13. Now, I'll use a python script to find the remaining ones and \"\n",
      "         'calculate the sum.\\n'\n",
      "         '\\n'}\n",
      "-----\n",
      "{'executable_code': {'code': 'def is_prime(n):\\n'\n",
      "                             '  \"\"\"Efficiently determine if n is prime.\"\"\"\\n'\n",
      "                             '  if n <= 1:\\n'\n",
      "                             '    return False\\n'\n",
      "                             '  if n <= 3:\\n'\n",
      "                             '    return True\\n'\n",
      "                             '  if n % 2 == 0 or n % 3 == 0:\\n'\n",
      "                             '    return False\\n'\n",
      "                             '  i = 5\\n'\n",
      "                             '  while i * i <= n:\\n'\n",
      "                             '    if n % i == 0 or n % (i + 2) == 0:\\n'\n",
      "                             '      return False\\n'\n",
      "                             '    i += 6\\n'\n",
      "                             '  return True\\n'\n",
      "                             '\\n'\n",
      "                             '\\n'\n",
      "                             'primes = []\\n'\n",
      "                             'num = 3\\n'\n",
      "                             'while len(primes) < 14:\\n'\n",
      "                             '  if is_prime(num):\\n'\n",
      "                             '    primes.append(num)\\n'\n",
      "                             '  num += 2  # Check only odd numbers\\n'\n",
      "                             '\\n'\n",
      "                             \"print(f'{primes=}')\\n\"\n",
      "                             '\\n'\n",
      "                             'sum_of_primes = sum(primes)\\n'\n",
      "                             \"print(f'{sum_of_primes=}')\\n\",\n",
      "                     'language': 'PYTHON'}}\n",
      "-----\n",
      "{'code_execution_result': {'outcome': 'OUTCOME_OK',\n",
      "                           'output': 'primes=[3, 5, 7, 11, 13, 17, 19, 23, 29, '\n",
      "                                     '31, 37, 41, 43, 47]\\n'\n",
      "                                     'sum_of_primes=326\\n'}}\n",
      "-----\n",
      "{'text': 'The first 14 odd prime numbers are 3, 5, 7, 11, 13, 17, 19, 23, 29, '\n",
      "         '31, 37, 41, 43, and 47.\\n'\n",
      "         '\\n'\n",
      "         'Their sum is 326.\\n'}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[types.Tool(code_execution=types.ToolCodeExecution())],\n",
    ")\n",
    "\n",
    "code_exec_prompt = \"\"\"\n",
    "Generate the first 14 odd prime numbers, then calculate their sum.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=config,\n",
    "    contents=code_exec_prompt)\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "  pprint(part.to_json_dict())\n",
    "  print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8fe411da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, I can do that. First, I need to generate the first 14 odd prime numbers. Then, I'll calculate their sum.\n",
       "\n",
       "Here's how I'll approach this:\n",
       "1.  Identify the first few odd prime numbers.\n",
       "2.  Continue identifying odd prime numbers until I have 14 of them. A prime number is a number greater than 1 that has only two factors: 1 and itself. An odd prime is simply a prime number that is odd.\n",
       "3.  Sum these 14 prime numbers.\n",
       "\n",
       "Let's start! The first few odd prime numbers are 3, 5, 7, 11, and 13. Now, I'll use a python script to find the remaining ones and calculate the sum.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def is_prime(n):\n",
       "  \"\"\"Efficiently determine if n is prime.\"\"\"\n",
       "  if n <= 1:\n",
       "    return False\n",
       "  if n <= 3:\n",
       "    return True\n",
       "  if n % 2 == 0 or n % 3 == 0:\n",
       "    return False\n",
       "  i = 5\n",
       "  while i * i <= n:\n",
       "    if n % i == 0 or n % (i + 2) == 0:\n",
       "      return False\n",
       "    i += 6\n",
       "  return True\n",
       "\n",
       "\n",
       "primes = []\n",
       "num = 3\n",
       "while len(primes) < 14:\n",
       "  if is_prime(num):\n",
       "    primes.append(num)\n",
       "  num += 2  # Check only odd numbers\n",
       "\n",
       "print(f'{primes=}')\n",
       "\n",
       "sum_of_primes = sum(primes)\n",
       "print(f'{sum_of_primes=}')\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "primes=[3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\n",
       "sum_of_primes=326\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The first 14 odd prime numbers are 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, and 47.\n",
       "\n",
       "Their sum is 326.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for part in response.candidates[0].content.parts:\n",
    "    if part.text:\n",
    "        display(Markdown(part.text))\n",
    "    elif part.executable_code:\n",
    "        display(Markdown(f'```python\\n{part.executable_code.code}\\n```'))\n",
    "    elif part.code_execution_result:\n",
    "        if part.code_execution_result.outcome != 'OUTCOME_OK':\n",
    "            display(Markdown(f'## Status {part.code_execution_result.outcome}'))\n",
    "\n",
    "        display(Markdown(f'```\\n{part.code_execution_result.output}\\n```'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a2d31c",
   "metadata": {},
   "source": [
    "## Explaining Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "adfdff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This file, `git-prompt.sh`, is a Bash script designed to enhance your command-line prompt by displaying information about the Git repository you're currently working in.\n",
       "\n",
       "**In simple terms:** It customizes your shell prompt to show things like the branch you're on, whether there are uncommitted changes, if you're ahead or behind the remote repository, and more.\n",
       "\n",
       "**Why would you use it?**\n",
       "\n",
       "*   **Context:**  Quickly see the status of your Git repository without needing to run `git status` constantly.\n",
       "*   **Efficiency:**  Makes you more aware of your Git state, potentially reducing errors and improving your workflow.\n",
       "*   **Customization:**  Offers a way to tweak the appearance of your prompt with themes and color options.\n",
       "\n",
       "Essentially, it's a visual aid that helps you stay on top of your Git repositories directly from your command line.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_contents = !curl https://raw.githubusercontent.com/magicmonty/bash-git-prompt/refs/heads/master/gitprompt.sh\n",
    "\n",
    "explain_prompt = f\"\"\"\n",
    "Please explain what this file does at a very high level. What is it, and why would I use it?\n",
    "\n",
    "```\n",
    "{file_contents}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=explain_prompt)\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a00548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
